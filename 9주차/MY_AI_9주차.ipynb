{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm\n",
        "!pip install surprise\n",
        "!pip install -U mlxtend"
      ],
      "metadata": {
        "id": "raL1Knaw6p6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#\n",
        "import mlxtend\n",
        "from surprise import Reader, Dataset, accuracy, SVD\n",
        "#from surprise.model_selection import train_test_split, GridSearchCV\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "from mlxtend.frequent_patterns import fpgrowth\n",
        "from mlxtend.frequent_patterns import association_rules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5Qiscg117sl",
        "outputId": "cd17a6b5-76b8-43fd-ce84-39884d5f1105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transObj(df):\n",
        "  le = LabelEncoder()\n",
        "  for x in df:\n",
        "      if df[x].dtypes=='object':\n",
        "          df[x] = le.fit_transform(df[x])\n",
        "  return df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYN-gNh6wC6y",
        "outputId": "0bc77194-d9ac-4fd6-dbcf-792aa23963d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: 보험 가격 예측\n",
        "\n",
        "# 결과\n",
        "# RMSE: 1579.5409127178361\n",
        "\n",
        "Mm = pd.read_csv(\"Medicalpremium.csv\");\n",
        "\n",
        "y = Mm.PremiumPrice\n",
        "X = Mm.drop(\"PremiumPrice\", axis=1)\n",
        "\n",
        "# 1_1 전처리\n",
        "# 1_1_1 결측치 처리\n",
        "\n",
        "#print(Mm.isnull().sum() / Mm.isna().sum())\n",
        "#결과: 없음 생략\n",
        "\n",
        "# 1_2 스케일링\n",
        "Mm_scaled = MinMaxScaler().fit_transform( X )\n",
        "\n",
        "# 1_3 파티셔닝\n",
        "X_train, X_test, y_train, y_test = train_test_split( Mm_scaled, y, test_size=0.2)\n",
        "\n",
        "# 1_4 fit\n",
        "# 1_4_1 모델 및 파라메타 선정\n",
        "# 모델: MLA 확인시  LGBMClassifier가 가장 좋다고 나옴\n",
        "# 파라메타: 디폴트가 제일 좋다고 나옴 0.1 / 100\n",
        "\n",
        "# 파라메타 검색\n",
        "# lgbm_params = {\"learning_rate\": [0.1, 0.3, 0.5, 0.7,1.0], \"n_estimators\":[100,200,300]}\n",
        "# c2_lgbm = GridSearchCV(LGBMClassifier(), lgbm_params).fit(X_train, y_train)\n",
        "# c2_lgbm.best_params_\n",
        "\n",
        "model = LGBMClassifier().fit( X_train, y_train )\n",
        "\n",
        "# 1_5 RMSE\n",
        "print(\"RMSE - \", np.sqrt( np.mean( (model.predict( X_test) - y_test)**2 ) ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ta0W3vN2MgD",
        "outputId": "8ab828ca-5148-43a9-d294-e51857d4e9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "RMSE -  1579.5409127178361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 신용카드 승인 분류\n",
        "\n",
        "# 결과\n",
        "# 정확도 accuracy: 0.992\n",
        "# 정밀도 precision: 0.550\n",
        "# 재현율 recall: 0.177\n",
        "\n",
        "\n",
        "# status 설명\n",
        "# 0: 1-29일 연체\n",
        "# 1: 30-59일 연체\n",
        "# 2: 60-89일 연체\n",
        "# 3: 90-119일 연체\n",
        "# 4: 120-149일 연체\n",
        "# 5: 연체 또는 부실 채권, 150일 이상 상각\n",
        "# C: 그 달에 상환\n",
        "# X: 해당 월에 대출 없음\n",
        "\n",
        "ar = pd.read_csv(\"application_record.csv\")\n",
        "cr = pd.read_csv(\"credit_record.csv\")\n",
        "\n",
        "# 2_1 전처리\n",
        "# 2_1_1 중복제거\n",
        "# print(ar['ID'].nunique())\n",
        "ar = ar.drop_duplicates('ID', keep='last')\n",
        "\n",
        "# 2_1_2 결측 OCCUPATION_TYPE에만 있음\n",
        "ar['OCCUPATION_TYPE'] = ar['OCCUPATION_TYPE'].fillna('others')\n",
        "\n",
        "# 2_1_3 Object 값을 라벨링\n",
        "le = LabelEncoder()\n",
        "transObj(ar)\n",
        "\n",
        "\n",
        "# 2_1_4 status 변경\n",
        "cr['STATUS'].replace({'C': 0, 'X': 0, '0' : 0, '1': 0, '2': 0}, inplace=True)\n",
        "cr['STATUS'].replace({'3': 1, '4': 1, '5' : 1}, inplace=True)\n",
        "ar['DAYS_EMPLOYED'] = ar['DAYS_EMPLOYED'].apply(lambda x:1 if x > 0 else 0)\n",
        "\n",
        "# 2_1_5 group by 및 df 합치기\n",
        "crGroup = cr.groupby('ID').agg(max).reset_index()\n",
        "data = ar.join(crGroup.set_index('ID'), on='ID', how='inner')\n",
        "\n",
        "y = data.STATUS\n",
        "X = data.drop(\"STATUS\", axis=1)\n",
        "\n",
        "# 2_2 스케일링\n",
        "ar_scaled = MinMaxScaler().fit_transform( X )\n",
        "\n",
        "# 2_3 파티셔닝\n",
        "X_train, X_test, y_train, y_test = train_test_split( ar_scaled, y, test_size=0.2)\n",
        "\n",
        "# 2_4 오버샘플링 안하는게 나음\n",
        "oversample = SMOTE(sampling_strategy = 1 ,k_neighbors = 1)\n",
        "xTrainB, yTrainB = oversample.fit_resample(X_train, y_train)\n",
        "\n",
        "model1 = LGBMClassifier().fit( X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "\n",
        "print('정확도 accuracy: %.3f' % accuracy_score(y_test, y_pred1))\n",
        "print('정밀도 precision: %.3f' % precision_score(y_true= y_test, y_pred=y_pred1))\n",
        "print('재현율 recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XcBCGvb5pC8",
        "outputId": "9d4aa60f-d8ca-42d8-b2da-ce53e2c4b394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "<ipython-input-49-d2b275ae7e76>:28: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ar['OCCUPATION_TYPE'] = ar['OCCUPATION_TYPE'].fillna('others')\n",
            "<ipython-input-29-922f656a3aa6>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[x] = le.fit_transform(df[x])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 accuracy: 0.992\n",
            "정밀도 precision: 0.565\n",
            "재현율 recall: 0.217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 은행 마케팅\n",
        "\n",
        "# 결과\n",
        "# 정확도 accuracy: 0.901\n",
        "# 정밀도 precision: 0.624\n",
        "# 재현율 recall: 0.428\n",
        "\n",
        "bf = pd.read_csv(\"bank-full.csv\")\n",
        "transObj(bf)\n",
        "\n",
        "y = bf.y\n",
        "X = bf.drop(\"y\", axis=1)\n",
        "\n",
        "# 3_1 전처리\n",
        "# 3_1_1 결측치 없음\n",
        "\n",
        "# 3_2 스케일링\n",
        "bf_scaled = MinMaxScaler().fit_transform( X )\n",
        "\n",
        "# 3_3 파티셔닝\n",
        "X_train, X_test, y_train, y_test = train_test_split(bf_scaled, y, test_size=0.2)\n",
        "\n",
        "model = RandomForestClassifier().fit( X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('정확도 accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
        "print('정밀도 precision: %.3f' % precision_score(y_true= y_test, y_pred=y_pred))\n",
        "print('재현율 recall: %.3f' % recall_score(y_true=y_test, y_pred=y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTv3WqYxaLgF",
        "outputId": "ae256d16-3bd9-4400-bd1b-52b2454e40d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도 accuracy: 0.901\n",
            "정밀도 precision: 0.624\n",
            "재현율 recall: 0.428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RMSE: 3.4598\n",
        "#RMSE: 3.4612\n",
        "book = pd.read_csv(\"BX-Book-Ratings._utf8.csv\", sep=\";\")\n",
        "book = book.dropna(how = 'any')\n",
        "\n",
        "reader = Reader(rating_scale=(0.0, 10.0))\n",
        "data = Dataset.load_from_df(book[['User-ID', 'ISBN', 'Book-Rating']], reader)\n",
        "\n",
        "train, test = train_test_split(data)\n",
        "\n",
        "algo = SVD(n_epochs=60, n_factors=300)\n",
        "algo.fit(train)\n",
        "pred = algo.test( test )\n",
        "accuracy.rmse(pred)\n",
        "\n",
        "algo = SVD(n_epochs=40, n_factors=300)\n",
        "algo.fit(train)\n",
        "pred = algo.test( test )\n",
        "accuracy.rmse(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1A-TGXrzZ8p",
        "outputId": "4f37091a-aba3-4bff-9a11-7cbb0e9abee6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 3.4449\n",
            "RMSE: 3.4481\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.4481088240608577"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ID\tITEM\tTIMESTAMP\n",
        "m1 = pd.read_csv(\"Behance_appreciate_1M\", header=None, sep=\" \", names=[\"ID\",\"ITEM\",\"TIMESTAMP\"])\n",
        "\n",
        "m1Group = m1.groupby('ID')['ITEM'].apply(set).apply(list).to_list()\n",
        "\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit_transform(m1Group)\n",
        "\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6u7k7sg-K3k",
        "outputId": "f5167262-a05e-4a24-c5fe-93b0522d8277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets = apriori(df, min_support=0.005, use_colnames=True)\n",
        "frequent_itemsets.sort_values(by='support', ascending=False)\n",
        "\n",
        "ar1 = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1).sort_values(by = ['confidence', 'lift', 'support'], ascending=False)\n",
        "ar2 = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1).sort_values(by = [ 'lift', 'confidence', 'support'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8LNQ7QAPiU6",
        "outputId": "3a2448dc-4201-4d80-c102-6e66fa31406e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ar1)\n",
        "print(ar2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDXkeg7nQtGp",
        "outputId": "e8c86eac-f3f0-4437-b292-c95d4701b140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   antecedents  consequents  antecedent support  consequent support   support  \\\n",
            "0  (1489915.0)  (1316541.0)            0.013791            0.029017  0.006212   \n",
            "1  (1316541.0)  (1489915.0)            0.029017            0.013791  0.006212   \n",
            "\n",
            "   confidence       lift  leverage  conviction  zhangs_metric  \n",
            "0    0.450407  15.521969  0.005811    1.766729       0.948658  \n",
            "1    0.214065  15.521969  0.005811    1.254822       0.963534  \n",
            "   antecedents  consequents  antecedent support  consequent support   support  \\\n",
            "0  (1489915.0)  (1316541.0)            0.013791            0.029017  0.006212   \n",
            "1  (1316541.0)  (1489915.0)            0.029017            0.013791  0.006212   \n",
            "\n",
            "   confidence       lift  leverage  conviction  zhangs_metric  \n",
            "0    0.450407  15.521969  0.005811    1.766729       0.948658  \n",
            "1    0.214065  15.521969  0.005811    1.254822       0.963534  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets2 = fpgrowth(df, min_support=0.005, use_colnames=True)\n",
        "frequent_itemsets2.sort_values(by='support', ascending=False)\n",
        "\n",
        "fr1 = association_rules(frequent_itemsets2, metric=\"confidence\", min_threshold=0.1).sort_values(by = ['confidence', 'lift', 'support'], ascending=False)\n",
        "fr2 = association_rules(frequent_itemsets2, metric=\"lift\", min_threshold=1).sort_values(by = [ 'lift', 'confidence', 'support'], ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO1fzOTENqW9",
        "outputId": "07badf8c-3cba-4112-df2b-d17be6fa1819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fr1)\n",
        "print(fr2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR3kUH6SPFFw",
        "outputId": "bc8a548d-d12f-4b52-d70e-8ef7915ef595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   antecedents  consequents  antecedent support  consequent support   support  \\\n",
            "0  (1489915.0)  (1316541.0)            0.013791            0.029017  0.006212   \n",
            "1  (1316541.0)  (1489915.0)            0.029017            0.013791  0.006212   \n",
            "\n",
            "   confidence       lift  leverage  conviction  zhangs_metric  \n",
            "0    0.450407  15.521969  0.005811    1.766729       0.948658  \n",
            "1    0.214065  15.521969  0.005811    1.254822       0.963534  \n",
            "   antecedents  consequents  antecedent support  consequent support   support  \\\n",
            "0  (1489915.0)  (1316541.0)            0.013791            0.029017  0.006212   \n",
            "1  (1316541.0)  (1489915.0)            0.029017            0.013791  0.006212   \n",
            "\n",
            "   confidence       lift  leverage  conviction  zhangs_metric  \n",
            "0    0.450407  15.521969  0.005811    1.766729       0.948658  \n",
            "1    0.214065  15.521969  0.005811    1.254822       0.963534  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn import feature_selection\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "\n",
        "X = X_train\n",
        "y = y_train\n",
        "\n",
        "#다양한 분류모형 비교\n",
        "from sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "MLA = [\n",
        "    #Tree, Ensemble Methods\n",
        "    tree.DecisionTreeClassifier(),\n",
        "    XGBClassifier(),\n",
        "    LGBMClassifier(),\n",
        "    ensemble.AdaBoostClassifier(),\n",
        "    ensemble.GradientBoostingClassifier(),\n",
        "    ensemble.RandomForestClassifier(),\n",
        "\n",
        "    #GLM\n",
        "    linear_model.LogisticRegressionCV(),\n",
        "\n",
        "    #Nearest Neighbor\n",
        "    KNeighborsClassifier()]\n",
        "#http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n",
        "\n",
        "#train_test_split보다 편하게 여러개 생성 가능 (10개를 만들거임 60:30으로 10은 뺴두기)\n",
        "cv_split = model_selection.ShuffleSplit(n_splits = 5, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n",
        "\n",
        "#MLA 비교\n",
        "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
        "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
        "\n",
        "#create table to compare MLA predictions\n",
        "MLA_predict = pd.DataFrame(y)\n",
        "\n",
        "#index through MLA and save performance to table\n",
        "row_index = 0\n",
        "for alg in MLA:\n",
        "\n",
        "    #set name and parameters\n",
        "    MLA_name = alg.__class__.__name__\n",
        "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
        "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
        "\n",
        "    #CV score: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate\n",
        "    cv_results = model_selection.cross_validate(alg, X, y, cv  = cv_split,return_train_score=True)\n",
        "\n",
        "    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()\n",
        "    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n",
        "    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n",
        "\n",
        "    #save MLA predictions\n",
        "    alg.fit(X, y)\n",
        "    MLA_predict[MLA_name] = alg.predict(X)\n",
        "    row_index+=1\n",
        "\n",
        "\n",
        "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
        "MLA_compare"
      ],
      "metadata": {
        "id": "6mNYqHHyHXls"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}